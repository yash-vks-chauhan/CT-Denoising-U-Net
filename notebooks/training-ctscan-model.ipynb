{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport cv2\nfrom tqdm import tqdm\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nimport pandas as pd\nimport seaborn as sns\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Paths to the dataset - make sure these are correct\nclean_img_path = \"/kaggle/input/lung-train-model/Train/Train/Clean\"\nnoisy_img_path = \"/kaggle/input/lung-train-model/Train/Train/Noisy\"\n\n# Image parameters\nIMG_HEIGHT = 256\nIMG_WIDTH = 256\nIMG_CHANNELS = 1  # Grayscale images\n\ndef check_dataset_paths():\n    \"\"\"Validates dataset paths and prints diagnostic information\"\"\"\n    print(\"\\n=== DATASET PATH VALIDATION ===\")\n    print(f\"Clean directory path: {clean_img_path}\")\n    print(f\"Clean directory exists: {os.path.exists(clean_img_path)}\")\n    print(f\"Noisy directory path: {noisy_img_path}\")\n    print(f\"Noisy directory exists: {os.path.exists(noisy_img_path)}\")\n    \n    if not os.path.exists(clean_img_path):\n        raise ValueError(f\"Clean directory does not exist: {clean_img_path}\")\n    if not os.path.exists(noisy_img_path):\n        raise ValueError(f\"Noisy directory does not exist: {noisy_img_path}\")\n    \n    clean_files = os.listdir(clean_img_path)\n    noisy_files = os.listdir(noisy_img_path)\n    \n    print(f\"Clean files found: {len(clean_files)}\")\n    print(f\"Noisy files found: {len(noisy_files)}\")\n    \n    if clean_files:\n        print(f\"Example clean files: {clean_files[:3]}\")\n    else:\n        raise ValueError(f\"No files found in clean directory: {clean_img_path}\")\n    \n    if noisy_files:\n        print(f\"Example noisy files: {noisy_files[:3]}\")\n    else:\n        raise ValueError(f\"No files found in noisy directory: {noisy_img_path}\")\n    \n    print(\"Dataset path validation successful.\\n\")\n    return clean_files, noisy_files\n\ndef extract_base_name(filename):\n    \"\"\"Extract the base name from a possibly augmented filename\"\"\"\n    # Split by common augmentation markers\n    if '_aug' in filename:\n        return filename.split('_aug')[0]\n    if '-aug' in filename:\n        return filename.split('-aug')[0]\n    # Strip common file extensions\n    base_name = os.path.splitext(filename)[0]\n    return base_name\n\ndef find_matching_pairs(clean_files, noisy_files):\n    \"\"\"Find matching file pairs using flexible matching\"\"\"\n    print(\"Finding matching file pairs...\")\n    \n    # Try exact matching first (with handling for augmentation)\n    clean_file_map = {}\n    for clean_file in clean_files:\n        base_name = extract_base_name(clean_file)\n        clean_file_map[base_name] = clean_file\n    \n    print(f\"Created {len(clean_file_map)} unique base names from clean files\")\n    \n    # Find matching files between clean and noisy\n    matched_pairs = []\n    for noisy_file in noisy_files:\n        base_name = extract_base_name(noisy_file)\n        if base_name in clean_file_map:\n            matched_pairs.append((clean_file_map[base_name], noisy_file))\n    \n    print(f\"Found {len(matched_pairs)} matched image pairs\")\n    \n    # If no matches found, try a more flexible matching approach\n    if len(matched_pairs) == 0:\n        print(\"No matches found with strict matching, trying fuzzy matching...\")\n        for noisy_file in noisy_files:\n            noisy_base = extract_base_name(noisy_file)\n            # Look for any clean file that contains the noisy base name\n            for clean_file in clean_files:\n                clean_base = extract_base_name(clean_file)\n                if noisy_base in clean_base or clean_base in noisy_base:\n                    matched_pairs.append((clean_file, noisy_file))\n                    break\n        \n        print(f\"Found {len(matched_pairs)} matched pairs with fuzzy matching\")\n    \n    # Last resort - just pair files sequentially if they have the same count\n    if len(matched_pairs) == 0 and len(clean_files) == len(noisy_files):\n        print(\"Using sequential matching as last resort...\")\n        clean_sorted = sorted(clean_files)\n        noisy_sorted = sorted(noisy_files)\n        matched_pairs = list(zip(clean_sorted, noisy_sorted))\n        print(f\"Created {len(matched_pairs)} sequential pairs\")\n    \n    if len(matched_pairs) == 0:\n        raise ValueError(\"Unable to find matching file pairs between clean and noisy directories\")\n    \n    return matched_pairs\n\ndef create_data_generator(clean_path, noisy_path, matched_pairs=None, batch_size=16):\n    \"\"\"Create a generator that yields batches of images with handling for augmented filenames\"\"\"\n    if matched_pairs is None:\n        clean_files = sorted(os.listdir(clean_path))\n        noisy_files = sorted(os.listdir(noisy_path))\n        matched_pairs = find_matching_pairs(clean_files, noisy_files)\n    \n    print(f\"Data generator created with {len(matched_pairs)} matched image pairs\")\n    num_samples = len(matched_pairs)\n\n    indices = np.arange(num_samples)\n\n    while True:\n        # Shuffle indices each epoch\n        np.random.shuffle(indices)\n\n        for start_idx in range(0, num_samples, batch_size):\n            batch_indices = indices[start_idx:start_idx + batch_size]\n\n            batch_clean = np.zeros((len(batch_indices), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n            batch_noisy = np.zeros((len(batch_indices), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n\n            for i, idx in enumerate(batch_indices):\n                clean_file, noisy_file = matched_pairs[idx]\n                \n                # Read and preprocess clean image\n                clean_path_full = os.path.join(clean_path, clean_file)\n                clean_img = cv2.imread(clean_path_full, cv2.IMREAD_GRAYSCALE)\n                if clean_img is None:\n                    print(f\"Warning: Could not read clean image: {clean_path_full}\")\n                    continue\n                clean_img = cv2.resize(clean_img, (IMG_WIDTH, IMG_HEIGHT))\n                clean_img = clean_img / 255.0  # Normalize to [0,1]\n\n                # Read and preprocess noisy image\n                noisy_path_full = os.path.join(noisy_path, noisy_file)\n                noisy_img = cv2.imread(noisy_path_full, cv2.IMREAD_GRAYSCALE)\n                if noisy_img is None:\n                    print(f\"Warning: Could not read noisy image: {noisy_path_full}\")\n                    continue\n                noisy_img = cv2.resize(noisy_img, (IMG_WIDTH, IMG_HEIGHT))\n                noisy_img = noisy_img / 255.0  # Normalize to [0,1]\n\n                batch_clean[i] = clean_img.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n                batch_noisy[i] = noisy_img.reshape(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n\n            yield batch_noisy, batch_clean\n\ndef load_validation_data(clean_path, noisy_path, matched_pairs=None, validation_split=0.2):\n    \"\"\"Load a smaller validation dataset for evaluation with handling for augmented filenames\"\"\"\n    if matched_pairs is None:\n        clean_files = sorted(os.listdir(clean_path))\n        noisy_files = sorted(os.listdir(noisy_path))\n        matched_pairs = find_matching_pairs(clean_files, noisy_files)\n    \n    print(f\"Using {len(matched_pairs)} matched image pairs for validation split\")\n    \n    # Split the data\n    train_files, val_files = train_test_split(\n        matched_pairs,\n        test_size=validation_split,\n        random_state=42\n    )\n    \n    print(f\"Split into {len(train_files)} training pairs and {len(val_files)} validation pairs\")\n    \n    # Load only validation data into memory\n    val_clean = []\n    val_noisy = []\n    val_names = []\n    \n    for clean_file, noisy_file in tqdm(val_files, desc=\"Loading validation data\"):\n        # Process clean image\n        clean_path_full = os.path.join(clean_path, clean_file)\n        clean_img = cv2.imread(clean_path_full, cv2.IMREAD_GRAYSCALE)\n        if clean_img is None:\n            print(f\"Warning: Could not read validation clean image: {clean_path_full}\")\n            continue\n        clean_img = cv2.resize(clean_img, (IMG_WIDTH, IMG_HEIGHT))\n        clean_img = clean_img / 255.0\n        \n        # Process noisy image\n        noisy_path_full = os.path.join(noisy_path, noisy_file)\n        noisy_img = cv2.imread(noisy_path_full, cv2.IMREAD_GRAYSCALE)\n        if noisy_img is None:\n            print(f\"Warning: Could not read validation noisy image: {noisy_path_full}\")\n            continue\n        noisy_img = cv2.resize(noisy_img, (IMG_WIDTH, IMG_HEIGHT))\n        noisy_img = noisy_img / 255.0\n        \n        val_clean.append(clean_img)\n        val_noisy.append(noisy_img)\n        val_names.append(clean_file)  # Store clean file name for reference\n    \n    if not val_clean:\n        raise ValueError(\"No validation images could be loaded. Check file paths and image formats.\")\n    \n    # Convert to numpy arrays\n    val_clean = np.array(val_clean).reshape(-1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS).astype(np.float32)\n    val_noisy = np.array(val_noisy).reshape(-1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS).astype(np.float32)\n    \n    return val_noisy, val_clean, val_names, len(train_files)\n\ndef build_optimized_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n    \"\"\"Build a more efficient U-Net model for image denoising\"\"\"\n    inputs = Input(input_shape)\n\n    # Encoder - with fewer filters and efficient blocks\n    def encoder_block(x, filters, kernel_size=3, batch_norm=True, pool=True):\n        conv = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n        if batch_norm:\n            conv = BatchNormalization()(conv)\n        conv = Activation('relu')(conv)\n        conv = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(conv)\n        if batch_norm:\n            conv = BatchNormalization()(conv)\n        conv = Activation('relu')(conv)\n\n        if pool:\n            pool_layer = MaxPooling2D(pool_size=(2, 2))(conv)\n            return conv, pool_layer\n        return conv\n\n    # Encoder path\n    conv1, pool1 = encoder_block(inputs, 32)\n    conv2, pool2 = encoder_block(pool1, 64)\n    conv3, pool3 = encoder_block(pool2, 128)\n    conv4, pool4 = encoder_block(pool3, 256)\n\n    # Bridge\n    conv5 = encoder_block(pool4, 512, pool=False)\n\n    # Decoder path\n    def decoder_block(x, skip_connection, filters, kernel_size=3, batch_norm=True):\n        up = UpSampling2D(size=(2, 2))(x)\n        up = Conv2D(filters, 2, padding='same', kernel_initializer='he_normal')(up)\n        up = Activation('relu')(up)\n\n        # Concatenate with skip connection\n        merge = Concatenate()([up, skip_connection])\n\n        conv = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(merge)\n        if batch_norm:\n            conv = BatchNormalization()(conv)\n        conv = Activation('relu')(conv)\n\n        conv = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(conv)\n        if batch_norm:\n            conv = BatchNormalization()(conv)\n        conv = Activation('relu')(conv)\n\n        return conv\n\n    # Decoder blocks\n    decoder6 = decoder_block(conv5, conv4, 256)\n    decoder7 = decoder_block(decoder6, conv3, 128)\n    decoder8 = decoder_block(decoder7, conv2, 64)\n    decoder9 = decoder_block(decoder8, conv1, 32)\n\n    # Output\n    outputs = Conv2D(IMG_CHANNELS, (1, 1), activation='sigmoid')(decoder9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n\n    return model\n\ndef train_model_with_generator(model_builder, train_gen, val_data, batch_size=16, steps_per_epoch=None, epochs=50):\n    \"\"\"Train the model using a generator for memory efficiency\"\"\"\n    # Unpack validation data\n    X_val, y_val, _, num_train_samples = val_data\n\n    if steps_per_epoch is None:\n        steps_per_epoch = max(1, num_train_samples // batch_size)\n        print(f\"Auto-calculated steps_per_epoch = {steps_per_epoch}\")\n\n    # Build model\n    model = model_builder()\n\n    # Print model summary\n    print(\"\\nModel Summary:\")\n    model.summary()\n    print(\"Model summary printed.\")\n\n    # Compile model with mixed precision\n    optimizer = Adam(learning_rate=1e-3)\n    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n\n    # Callbacks\n    callbacks = [\n        ModelCheckpoint('best_denoising_model.keras', save_best_only=True, monitor='val_loss'),\n        EarlyStopping(patience=10, restore_best_weights=True),\n        ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)\n    ]\n\n    # Train with generator\n    print(\"Starting model training with model.fit...\")\n    history = model.fit(\n        train_gen,\n        steps_per_epoch=steps_per_epoch,\n        epochs=epochs,\n        validation_data=(X_val, y_val),\n        callbacks=callbacks,\n        \n    )\n    print(\"model.fit call completed.\")\n\n    return model, history\n\ndef calculate_improvement_metrics(X_test, y_test, predictions, image_names=None):\n    \"\"\"Calculate comprehensive metrics for model evaluation\"\"\"\n    metrics_list = []\n\n    for i in range(len(predictions)):\n        # Convert to [0,1] format\n        noisy_img = X_test[i].reshape(IMG_HEIGHT, IMG_WIDTH)\n        clean_img = y_test[i].reshape(IMG_HEIGHT, IMG_WIDTH)\n        pred_img = predictions[i].reshape(IMG_HEIGHT, IMG_WIDTH)\n\n        # Ensure all images have the same dtype\n        noisy_img = noisy_img.astype(np.float32)\n        clean_img = clean_img.astype(np.float32)\n        pred_img = pred_img.astype(np.float32)\n\n        # Calculate PSNR with data_range specified\n        noisy_psnr_val = psnr(clean_img, noisy_img, data_range=1.0)\n        denoised_psnr_val = psnr(clean_img, pred_img, data_range=1.0)\n        psnr_improvement = denoised_psnr_val - noisy_psnr_val\n\n        # Calculate SSIM with data_range specified\n        noisy_ssim_val = ssim(clean_img, noisy_img, data_range=1.0)\n        denoised_ssim_val = ssim(clean_img, pred_img, data_range=1.0)\n        ssim_improvement = denoised_ssim_val - noisy_ssim_val\n\n        # Calculate MSE\n        noisy_mse = np.mean((clean_img - noisy_img) ** 2)\n        denoised_mse = np.mean((clean_img - pred_img) ** 2)\n        mse_improvement = noisy_mse - denoised_mse\n\n        # Get image name, handling potential augmented file naming\n        if image_names:\n            image_id = image_names[i]\n            # Extract base name without augmentation suffix if needed\n            if '_aug' in image_id:\n                base_image_id = image_id.split('_aug')[0]\n            else:\n                base_image_id = image_id\n        else:\n            image_id = i\n            base_image_id = i\n\n        # Store metrics\n        metrics_dict = {\n            'image_id': image_id,\n            'base_image_id': base_image_id,\n            'noisy_psnr': noisy_psnr_val,\n            'denoised_psnr': denoised_psnr_val,\n            'psnr_improvement': psnr_improvement,\n            'psnr_improvement_percent': (psnr_improvement / noisy_psnr_val) * 100 if noisy_psnr_val > 0 else float('inf'),\n\n            'noisy_ssim': noisy_ssim_val,\n            'denoised_ssim': denoised_ssim_val,\n            'ssim_improvement': ssim_improvement,\n            'ssim_improvement_percent': (ssim_improvement / noisy_ssim_val) * 100 if noisy_ssim_val > 0 else float('inf'),\n\n            'noisy_mse': noisy_mse,\n            'denoised_mse': denoised_mse,\n            'mse_improvement': mse_improvement,\n            'mse_reduction_percent': (mse_improvement / noisy_mse) * 100 if noisy_mse > 0 else float('inf'),\n        }\n\n        metrics_list.append(metrics_dict)\n\n    # Create DataFrame\n    metrics_df = pd.DataFrame(metrics_list)\n\n    return metrics_df\n\ndef run_training_pipeline():\n    \"\"\"Execute the full optimized training pipeline\"\"\"\n    print(\"Starting optimized training pipeline...\")\n\n    # Validate dataset paths and get file lists\n    clean_files, noisy_files = check_dataset_paths()\n    \n    # Find matching pairs between clean and noisy images\n    matched_pairs = find_matching_pairs(clean_files, noisy_files)\n\n    # Set batch size\n    BATCH_SIZE = 16\n    EPOCHS = 50\n\n    # Load validation data (keeping this small to save memory)\n    val_data = load_validation_data(clean_img_path, noisy_img_path, matched_pairs, validation_split=0.15)\n    X_val, y_val, val_names, num_train_samples = val_data\n\n    # Test validation data loading\n    print(\"Testing validation data loading...\")\n    print(\"X_val shape:\", X_val.shape)\n    print(\"y_val shape:\", y_val.shape)\n    print(\"Number of validation samples:\", len(X_val))\n    print(\"Validation data loading test successful.\")\n\n    # Create training data generator\n    train_gen = create_data_generator(clean_img_path, noisy_img_path, matched_pairs, batch_size=BATCH_SIZE)\n\n    # Test the generator\n    print(\"Testing data generator...\")\n    sample_batch_noisy, sample_batch_clean = next(train_gen)\n    print(\"Sample noisy batch shape:\", sample_batch_noisy.shape)\n    print(\"Sample clean batch shape:\", sample_batch_clean.shape)\n    print(\"Generator test successful, data is being yielded in batches.\")\n\n    # Calculate steps per epoch\n    steps_per_epoch = max(1, num_train_samples // BATCH_SIZE)\n    print(f\"Training with {num_train_samples} samples, {steps_per_epoch} steps per epoch\")\n\n    # Train model\n    model, history = train_model_with_generator(\n        model_builder=build_optimized_unet,\n        train_gen=train_gen,\n        val_data=val_data,\n        batch_size=BATCH_SIZE,\n        steps_per_epoch=steps_per_epoch,\n        epochs=EPOCHS\n    )\n\n    # Plot training history\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['mae'])\n    plt.plot(history.history['val_mae'])\n    plt.title('Mean Absolute Error')\n    plt.ylabel('MAE')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper right')\n\n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.show()\n\n    # Generate predictions on validation set\n    print(\"Generating predictions on validation set...\")\n    predictions = model.predict(X_val, batch_size=BATCH_SIZE)\n\n    # Evaluate model\n    print(\"Calculating performance metrics...\")\n    metrics_df = calculate_improvement_metrics(X_val, y_val, predictions, val_names)\n\n    # Display sample results\n    if len(X_val) > 0:\n        sample_indices = np.random.choice(len(X_val), min(3, len(X_val)), replace=False)\n\n        plt.figure(figsize=(15, 5*len(sample_indices)))\n\n        for i, idx in enumerate(sample_indices):\n            # Display original noisy image\n            plt.subplot(len(sample_indices), 3, i*3+1)\n            plt.imshow(X_val[idx].reshape(IMG_HEIGHT, IMG_WIDTH), cmap='gray')\n            plt.title(f\"Sample {i+1}\\nNoisy Input\")\n            plt.axis('off')\n\n            # Display ground truth (clean image)\n            plt.subplot(len(sample_indices), 3, i*3+2)\n            plt.imshow(y_val[idx].reshape(IMG_HEIGHT, IMG_WIDTH), cmap='gray')\n            plt.title(\"Clean (Ground Truth)\")\n            plt.axis('off')\n\n            # Display model prediction\n            plt.subplot(len(sample_indices), 3, i*3+3)\n            plt.imshow(predictions[idx].reshape(IMG_HEIGHT, IMG_WIDTH), cmap='gray')\n            plt.title(\"Denoised (Predicted)\")\n            plt.axis('off')\n\n        plt.tight_layout()\n        plt.savefig('sample_results.png')\n        plt.show()\n\n    # Print summary statistics\n    print(\"\\n==== SUMMARY STATISTICS ====\")\n    print(f\"Average PSNR Improvement: {metrics_df['psnr_improvement'].mean():.2f} dB (± {metrics_df['psnr_improvement'].std():.2f})\")\n    print(f\"Average SSIM Improvement: {metrics_df['ssim_improvement'].mean():.4f} (± {metrics_df['ssim_improvement'].std():.4f})\")\n    print(f\"Average MSE Reduction: {metrics_df['mse_reduction_percent'].mean():.2f}% (± {metrics_df['mse_reduction_percent'].std():.2f}%)\")\n\n    print(\"\\n==== SUCCESS RATE ====\")\n    psnr_success = (metrics_df['psnr_improvement'] > 0).mean() * 100\n    ssim_success = (metrics_df['ssim_improvement'] > 0).mean() * 100\n    mse_success = (metrics_df['mse_improvement'] > 0).mean() * 100\n    print(f\"PSNR Improvement Success Rate: {psnr_success:.2f}%\")\n    print(f\"SSIM Improvement Success Rate: {ssim_success:.2f}%\")\n    print(f\"MSE Improvement Success Rate: {mse_success:.2f}%\")\n    \n    # Return model and metrics for further analysis if needed\n    return model, metrics_df\n\n# Main execution\nif __name__ == \"__main__\":\n    try:\n        # Run training pipeline\n        model, metrics_df = run_training_pipeline()\n        \n        # Optional: Save metrics to CSV\n        metrics_df.to_csv('denoising_metrics.csv', index=False)\n        \n        print(\"Training and evaluation complete!\")\n    except Exception as e:\n        print(f\"ERROR: {type(e).__name__}: {str(e)}\")\n        import traceback\n        traceback.print_exc()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}